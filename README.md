# Haghiri Code: An AI agent for making the software you're thinking of.

## Table of contents

- [Markdown Files](#markdown-files)
- [Problems with Gemini Results](#problems-with-gemini-results)

## Markdown Files

- [SCHEME.md](SCHEME.md): Scheme generated by Gemini.
- [GEMINI.md](GEMINI.md): Gemini 3 Pro's response on the _game plan_.
- [PROMPT.md](PROMPT.md): Prompt given to LLM (In this case, Gemini 3 Pro)

## Problems with Gemini Results

If you take a look at two files which are generated by Gemini, you can see a common problem with LLMs, specially these SOTA ones, which is _overcomplication_ of the simple stuff. For this project, I personally don't want to spend too much time unless it gains enough attention and contributors, otherwise it'll be like hundreds of other projects I posted on github, personal hobbies in rainy afternoons. However, let's see how these overcomplications can be detected:

1. Using too many libraries, while everything can be easily done using `openai` library and you even do not need _tool calling_ feature to be used. Although it is always wiser to use the tool calling functionalities of the models, but for the sake of simplicity, I won't do that.
2. For this project we're going to use _ReAct_ or _Repeat, Action_ framework of making agents. This also can be done through multiple libraries but again, I insist on the fact that it'll be better if I stick to OpenAI's library.
3. To make it much simpler than usual, what I'm going to do is basically reading the data from a file (markdown or txt, the file will be given to the thing using `argparse` library) and then the agent starts to make everything based on that. 
4. Another thought for simplicity is to limit the library to a language or framework, or one or two certain ones, one for backend or one for the frontend. Although this thing is not necessary since most of the models even small ones can understand multiple languages or frameworks.